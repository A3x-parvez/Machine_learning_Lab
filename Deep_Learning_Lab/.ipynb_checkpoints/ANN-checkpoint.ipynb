{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\itsri\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/390.3 MB 4.2 MB/s eta 0:01:33\n",
      "   ---------------------------------------- 2.6/390.3 MB 8.9 MB/s eta 0:00:44\n",
      "    --------------------------------------- 5.8/390.3 MB 11.4 MB/s eta 0:00:34\n",
      "    --------------------------------------- 8.9/390.3 MB 12.9 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 12.1/390.3 MB 13.3 MB/s eta 0:00:29\n",
      "   - -------------------------------------- 15.7/390.3 MB 14.1 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 16.3/390.3 MB 14.0 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 16.5/390.3 MB 12.0 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 18.9/390.3 MB 10.8 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 19.9/390.3 MB 10.5 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 19.9/390.3 MB 10.5 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 22.0/390.3 MB 9.3 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 23.1/390.3 MB 9.2 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 23.6/390.3 MB 8.4 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 24.4/390.3 MB 8.1 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 24.9/390.3 MB 8.0 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 26.5/390.3 MB 7.7 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 26.5/390.3 MB 7.7 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 27.8/390.3 MB 7.3 MB/s eta 0:00:50\n",
      "   -- ------------------------------------- 28.6/390.3 MB 7.1 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 29.4/390.3 MB 6.9 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 30.7/390.3 MB 6.9 MB/s eta 0:00:53\n",
      "   --- ------------------------------------ 32.0/390.3 MB 6.9 MB/s eta 0:00:53\n",
      "   --- ------------------------------------ 32.8/390.3 MB 6.8 MB/s eta 0:00:53\n",
      "   --- ------------------------------------ 34.1/390.3 MB 6.7 MB/s eta 0:00:53\n",
      "   --- ------------------------------------ 34.6/390.3 MB 6.6 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 35.7/390.3 MB 6.5 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 37.0/390.3 MB 6.5 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 38.3/390.3 MB 6.5 MB/s eta 0:00:55\n",
      "   ---- ----------------------------------- 39.8/390.3 MB 6.5 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 41.4/390.3 MB 6.6 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 42.7/390.3 MB 6.5 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 44.3/390.3 MB 6.6 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 45.9/390.3 MB 6.6 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 47.2/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 48.5/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 49.8/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 51.1/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 52.4/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 53.7/390.3 MB 6.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 54.8/390.3 MB 6.5 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 55.6/390.3 MB 6.4 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 56.4/390.3 MB 6.4 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 57.1/390.3 MB 6.3 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 57.7/390.3 MB 6.3 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 58.5/390.3 MB 6.2 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 59.5/390.3 MB 6.2 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 60.0/390.3 MB 6.1 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 61.1/390.3 MB 6.1 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 61.6/390.3 MB 6.0 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 62.4/390.3 MB 6.0 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 63.2/390.3 MB 5.9 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 64.0/390.3 MB 5.9 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 64.5/390.3 MB 5.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 65.3/390.3 MB 5.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 66.1/390.3 MB 5.7 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 66.6/390.3 MB 5.7 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 67.4/390.3 MB 5.7 MB/s eta 0:00:58\n",
      "   ------ --------------------------------- 68.2/390.3 MB 5.6 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 68.9/390.3 MB 5.6 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 69.7/390.3 MB 5.6 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 70.3/390.3 MB 5.5 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 71.0/390.3 MB 5.5 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 71.8/390.3 MB 5.5 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 72.6/390.3 MB 5.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 73.7/390.3 MB 5.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 74.4/390.3 MB 5.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 75.0/390.3 MB 5.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 75.8/390.3 MB 5.3 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 76.3/390.3 MB 5.3 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 77.3/390.3 MB 5.3 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 78.1/390.3 MB 5.3 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 79.2/390.3 MB 5.3 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 79.7/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 80.5/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 81.3/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 82.3/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 83.1/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 83.9/390.3 MB 5.2 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 84.7/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 85.7/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 86.5/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 87.3/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 88.1/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 88.9/390.3 MB 5.1 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 89.4/390.3 MB 5.0 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 89.4/390.3 MB 5.0 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 89.9/390.3 MB 5.0 MB/s eta 0:01:01\n",
      "   --------- ------------------------------ 90.2/390.3 MB 4.9 MB/s eta 0:01:02\n",
      "   --------- ------------------------------ 90.4/390.3 MB 4.9 MB/s eta 0:01:02\n",
      "   --------- ------------------------------ 91.0/390.3 MB 4.8 MB/s eta 0:01:02\n",
      "   --------- ------------------------------ 91.5/390.3 MB 4.8 MB/s eta 0:01:02\n",
      "   --------- ------------------------------ 91.8/390.3 MB 4.8 MB/s eta 0:01:03\n",
      "   --------- ------------------------------ 92.3/390.3 MB 4.8 MB/s eta 0:01:03\n",
      "   --------- ------------------------------ 92.5/390.3 MB 4.7 MB/s eta 0:01:04\n",
      "   --------- ------------------------------ 93.1/390.3 MB 4.7 MB/s eta 0:01:04\n",
      "   --------- ------------------------------ 93.6/390.3 MB 4.7 MB/s eta 0:01:04\n",
      "   --------- ------------------------------ 93.6/390.3 MB 4.7 MB/s eta 0:01:04\n",
      "   --------- ------------------------------ 94.4/390.3 MB 4.6 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 94.9/390.3 MB 4.6 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 95.2/390.3 MB 4.6 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 95.7/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 96.5/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   --------- ------------------------------ 97.0/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 97.8/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 98.8/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 99.6/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 100.7/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 101.4/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 102.2/390.3 MB 4.5 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 103.3/390.3 MB 4.5 MB/s eta 0:01:04\n",
      "   ---------- ----------------------------- 104.1/390.3 MB 4.5 MB/s eta 0:01:04\n",
      "   ---------- ----------------------------- 105.1/390.3 MB 4.5 MB/s eta 0:01:04\n",
      "   ---------- ----------------------------- 106.2/390.3 MB 4.5 MB/s eta 0:01:04\n",
      "   ---------- ----------------------------- 107.2/390.3 MB 4.5 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 108.3/390.3 MB 4.5 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 109.3/390.3 MB 4.5 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 110.6/390.3 MB 4.5 MB/s eta 0:01:02\n",
      "   ----------- ---------------------------- 111.7/390.3 MB 4.5 MB/s eta 0:01:02\n",
      "   ----------- ---------------------------- 112.7/390.3 MB 4.5 MB/s eta 0:01:02\n",
      "   ----------- ---------------------------- 113.8/390.3 MB 4.5 MB/s eta 0:01:01\n",
      "   ----------- ---------------------------- 114.8/390.3 MB 4.6 MB/s eta 0:01:01\n",
      "   ----------- ---------------------------- 115.9/390.3 MB 4.6 MB/s eta 0:01:01\n",
      "   ----------- ---------------------------- 116.9/390.3 MB 4.6 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 118.0/390.3 MB 4.6 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 119.0/390.3 MB 4.6 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 120.1/390.3 MB 4.6 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 121.1/390.3 MB 4.6 MB/s eta 0:00:59\n",
      "   ------------ --------------------------- 122.2/390.3 MB 4.6 MB/s eta 0:00:59\n",
      "   ------------ --------------------------- 123.2/390.3 MB 4.6 MB/s eta 0:00:59\n",
      "   ------------ --------------------------- 124.3/390.3 MB 4.6 MB/s eta 0:00:59\n",
      "   ------------ --------------------------- 125.0/390.3 MB 4.6 MB/s eta 0:00:58\n",
      "   ------------ --------------------------- 126.4/390.3 MB 4.6 MB/s eta 0:00:58\n",
      "   ------------- -------------------------- 127.4/390.3 MB 4.6 MB/s eta 0:00:58\n",
      "   ------------- -------------------------- 128.7/390.3 MB 4.6 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 129.5/390.3 MB 4.6 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 130.5/390.3 MB 4.6 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 131.3/390.3 MB 4.6 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 132.4/390.3 MB 4.6 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 133.2/390.3 MB 4.6 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 134.0/390.3 MB 4.6 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 134.7/390.3 MB 4.6 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 135.8/390.3 MB 4.6 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 136.8/390.3 MB 4.6 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 138.1/390.3 MB 4.6 MB/s eta 0:00:55\n",
      "   -------------- ------------------------- 139.2/390.3 MB 4.6 MB/s eta 0:00:55\n",
      "   -------------- ------------------------- 140.2/390.3 MB 4.5 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 141.3/390.3 MB 4.4 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 142.1/390.3 MB 4.4 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 143.1/390.3 MB 4.3 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 144.2/390.3 MB 4.3 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 145.5/390.3 MB 4.3 MB/s eta 0:00:57\n",
      "   --------------- ------------------------ 146.8/390.3 MB 4.3 MB/s eta 0:00:57\n",
      "   --------------- ------------------------ 148.1/390.3 MB 4.3 MB/s eta 0:00:57\n",
      "   --------------- ------------------------ 149.2/390.3 MB 4.3 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 150.5/390.3 MB 4.3 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 151.5/390.3 MB 4.3 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 152.8/390.3 MB 4.3 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 154.4/390.3 MB 4.4 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 155.7/390.3 MB 4.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 157.3/390.3 MB 4.4 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 158.1/390.3 MB 4.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 159.1/390.3 MB 4.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 160.4/390.3 MB 4.4 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 162.0/390.3 MB 4.4 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 163.8/390.3 MB 4.5 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 165.4/390.3 MB 4.5 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 167.0/390.3 MB 4.5 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 167.8/390.3 MB 4.5 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 169.3/390.3 MB 4.5 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 171.2/390.3 MB 4.5 MB/s eta 0:00:49\n",
      "   ----------------- ---------------------- 173.0/390.3 MB 4.5 MB/s eta 0:00:48\n",
      "   ----------------- ---------------------- 174.3/390.3 MB 4.5 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 175.6/390.3 MB 4.5 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 176.9/390.3 MB 4.5 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 179.0/390.3 MB 4.6 MB/s eta 0:00:47\n",
      "   ------------------ --------------------- 181.1/390.3 MB 4.6 MB/s eta 0:00:46\n",
      "   ------------------ --------------------- 183.5/390.3 MB 4.6 MB/s eta 0:00:45\n",
      "   ------------------ --------------------- 185.3/390.3 MB 4.6 MB/s eta 0:00:45\n",
      "   ------------------- -------------------- 187.2/390.3 MB 4.6 MB/s eta 0:00:44\n",
      "   ------------------- -------------------- 189.5/390.3 MB 4.7 MB/s eta 0:00:44\n",
      "   ------------------- -------------------- 191.1/390.3 MB 4.7 MB/s eta 0:00:43\n",
      "   ------------------- -------------------- 192.9/390.3 MB 4.7 MB/s eta 0:00:43\n",
      "   ------------------- -------------------- 194.5/390.3 MB 4.7 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 195.6/390.3 MB 4.7 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 196.6/390.3 MB 4.7 MB/s eta 0:00:42\n",
      "   -------------------- ------------------- 199.0/390.3 MB 4.8 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 200.8/390.3 MB 4.8 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 202.6/390.3 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 204.5/390.3 MB 4.9 MB/s eta 0:00:39\n",
      "   --------------------- ------------------ 205.8/390.3 MB 4.9 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 206.3/390.3 MB 4.9 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 208.1/390.3 MB 4.9 MB/s eta 0:00:38\n",
      "   --------------------- ------------------ 209.2/390.3 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 209.7/390.3 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 210.5/390.3 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 211.6/390.3 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 213.1/390.3 MB 5.0 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 214.4/390.3 MB 5.0 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 216.0/390.3 MB 5.0 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 217.8/390.3 MB 5.0 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 219.7/390.3 MB 5.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 221.2/390.3 MB 5.1 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 222.8/390.3 MB 5.1 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 224.9/390.3 MB 5.2 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 226.5/390.3 MB 5.2 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 228.3/390.3 MB 5.2 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 230.2/390.3 MB 5.3 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 232.0/390.3 MB 5.3 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 233.6/390.3 MB 5.3 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 235.7/390.3 MB 5.4 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 237.2/390.3 MB 5.4 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 238.8/390.3 MB 5.4 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 240.6/390.3 MB 5.5 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 242.5/390.3 MB 5.5 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 244.3/390.3 MB 5.5 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 245.4/390.3 MB 5.6 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 247.2/390.3 MB 5.6 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 249.3/390.3 MB 5.6 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 250.9/390.3 MB 5.7 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 253.0/390.3 MB 5.7 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 255.1/390.3 MB 5.7 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 256.9/390.3 MB 5.8 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 258.7/390.3 MB 5.8 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 260.6/390.3 MB 5.8 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 262.4/390.3 MB 5.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 264.0/390.3 MB 5.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 266.1/390.3 MB 5.9 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 267.9/390.3 MB 6.0 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 269.7/390.3 MB 6.0 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 271.6/390.3 MB 6.1 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 273.2/390.3 MB 6.1 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 274.7/390.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 276.6/390.3 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 278.4/390.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 280.0/390.3 MB 6.3 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 282.1/390.3 MB 6.4 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 283.4/390.3 MB 6.4 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 285.5/390.3 MB 6.4 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 287.3/390.3 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 289.4/390.3 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 291.2/390.3 MB 6.6 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 293.1/390.3 MB 6.6 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 295.2/390.3 MB 6.7 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 297.3/390.3 MB 6.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 299.1/390.3 MB 6.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 300.9/390.3 MB 6.8 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 303.0/390.3 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 305.1/390.3 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 307.0/390.3 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 309.1/390.3 MB 7.0 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 311.2/390.3 MB 7.0 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 313.3/390.3 MB 7.1 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 315.6/390.3 MB 7.1 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 317.7/390.3 MB 7.2 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 319.6/390.3 MB 7.2 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 321.9/390.3 MB 7.2 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 324.3/390.3 MB 7.3 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 326.4/390.3 MB 7.3 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 328.5/390.3 MB 7.4 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 331.1/390.3 MB 7.4 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 333.4/390.3 MB 7.4 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 335.5/390.3 MB 7.5 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 338.2/390.3 MB 7.5 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 340.8/390.3 MB 7.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 343.4/390.3 MB 7.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 346.3/390.3 MB 7.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 349.2/390.3 MB 7.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 351.5/390.3 MB 7.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 354.4/390.3 MB 7.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 357.6/390.3 MB 7.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 360.7/390.3 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 363.6/390.3 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 366.2/390.3 MB 8.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.1/390.3 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 372.2/390.3 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 375.1/390.3 MB 8.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 378.8/390.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.4/390.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  384.3/390.3 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  387.7/390.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.3 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.3/390.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 3.7/4.4 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 19.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.5/26.4 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.2/26.4 MB 17.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.6/26.4 MB 17.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.4 MB 17.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 18.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 17.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 4.5/5.5 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.69.0 keras-3.8.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hWLnPYlsbGRd",
    "outputId": "366cae3a-f81a-4c6d-f593-6e139bf8936c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "pMwgr7mDcXYx",
    "outputId": "81a58a16-a462-4746-b453-7968adb455f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9194829637648664790\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "eGNbs3Emc3cQ",
    "outputId": "182f92a5-e3c8-454d-aca9-de1f58447a02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "id": "Kbzav2Fkdpbp",
    "outputId": "38a9d164-9d09-45d5-98a7-ecd97c954baf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANbza7j9d0nL"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "## Concatenate the Data Frames\n",
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "\n",
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='he_uniform', activation='relu', input_dim=11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=6, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.6123 - loss: 0.7694 - val_acc: 0.7565 - val_loss: 0.5865\n",
      "Epoch 2/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7830 - loss: 0.5650 - val_acc: 0.7910 - val_loss: 0.5370\n",
      "Epoch 3/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7954 - loss: 0.5311 - val_acc: 0.7921 - val_loss: 0.5131\n",
      "Epoch 4/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7921 - loss: 0.5092 - val_acc: 0.7921 - val_loss: 0.4972\n",
      "Epoch 5/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7967 - loss: 0.4906 - val_acc: 0.7929 - val_loss: 0.4852\n",
      "Epoch 6/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8037 - loss: 0.4646 - val_acc: 0.7933 - val_loss: 0.4761\n",
      "Epoch 7/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8079 - loss: 0.4554 - val_acc: 0.7944 - val_loss: 0.4692\n",
      "Epoch 8/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8066 - loss: 0.4520 - val_acc: 0.7978 - val_loss: 0.4636\n",
      "Epoch 9/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7977 - loss: 0.4510 - val_acc: 0.7963 - val_loss: 0.4590\n",
      "Epoch 10/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8011 - loss: 0.4525 - val_acc: 0.7982 - val_loss: 0.4555\n",
      "Epoch 11/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8136 - loss: 0.4318 - val_acc: 0.7959 - val_loss: 0.4523\n",
      "Epoch 12/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8044 - loss: 0.4411 - val_acc: 0.7959 - val_loss: 0.4492\n",
      "Epoch 13/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8124 - loss: 0.4318 - val_acc: 0.7978 - val_loss: 0.4464\n",
      "Epoch 14/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8128 - loss: 0.4269 - val_acc: 0.7997 - val_loss: 0.4440\n",
      "Epoch 15/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - acc: 0.8142 - loss: 0.4315 - val_acc: 0.8005 - val_loss: 0.4414\n",
      "Epoch 16/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8337 - loss: 0.4041 - val_acc: 0.7993 - val_loss: 0.4393\n",
      "Epoch 17/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8096 - loss: 0.4377 - val_acc: 0.7989 - val_loss: 0.4374\n",
      "Epoch 18/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8187 - loss: 0.4156 - val_acc: 0.7997 - val_loss: 0.4355\n",
      "Epoch 19/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8209 - loss: 0.4140 - val_acc: 0.8023 - val_loss: 0.4334\n",
      "Epoch 20/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8162 - loss: 0.4168 - val_acc: 0.8031 - val_loss: 0.4315\n",
      "Epoch 21/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8284 - loss: 0.4056 - val_acc: 0.8046 - val_loss: 0.4296\n",
      "Epoch 22/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8194 - loss: 0.4165 - val_acc: 0.8092 - val_loss: 0.4277\n",
      "Epoch 23/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8283 - loss: 0.4006 - val_acc: 0.8099 - val_loss: 0.4254\n",
      "Epoch 24/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8276 - loss: 0.4006 - val_acc: 0.8095 - val_loss: 0.4236\n",
      "Epoch 25/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8189 - loss: 0.4157 - val_acc: 0.8084 - val_loss: 0.4218\n",
      "Epoch 26/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8290 - loss: 0.3948 - val_acc: 0.8099 - val_loss: 0.4199\n",
      "Epoch 27/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8249 - loss: 0.4015 - val_acc: 0.8133 - val_loss: 0.4181\n",
      "Epoch 28/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8243 - loss: 0.4055 - val_acc: 0.8133 - val_loss: 0.4164\n",
      "Epoch 29/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8330 - loss: 0.3971 - val_acc: 0.8141 - val_loss: 0.4150\n",
      "Epoch 30/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8398 - loss: 0.3859 - val_acc: 0.8167 - val_loss: 0.4138\n",
      "Epoch 31/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8341 - loss: 0.3994 - val_acc: 0.8190 - val_loss: 0.4120\n",
      "Epoch 32/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8367 - loss: 0.4015 - val_acc: 0.8213 - val_loss: 0.4104\n",
      "Epoch 33/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8412 - loss: 0.3856 - val_acc: 0.8205 - val_loss: 0.4088\n",
      "Epoch 34/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8394 - loss: 0.3896 - val_acc: 0.8228 - val_loss: 0.4069\n",
      "Epoch 35/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8319 - loss: 0.4012 - val_acc: 0.8209 - val_loss: 0.4048\n",
      "Epoch 36/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8429 - loss: 0.3810 - val_acc: 0.8254 - val_loss: 0.4029\n",
      "Epoch 37/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8431 - loss: 0.3772 - val_acc: 0.8273 - val_loss: 0.4013\n",
      "Epoch 38/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8334 - loss: 0.3909 - val_acc: 0.8258 - val_loss: 0.3992\n",
      "Epoch 39/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8462 - loss: 0.3719 - val_acc: 0.8270 - val_loss: 0.3970\n",
      "Epoch 40/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8436 - loss: 0.3765 - val_acc: 0.8285 - val_loss: 0.3948\n",
      "Epoch 41/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8387 - loss: 0.3852 - val_acc: 0.8304 - val_loss: 0.3927\n",
      "Epoch 42/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8489 - loss: 0.3651 - val_acc: 0.8307 - val_loss: 0.3910\n",
      "Epoch 43/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8488 - loss: 0.3724 - val_acc: 0.8326 - val_loss: 0.3892\n",
      "Epoch 44/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8523 - loss: 0.3646 - val_acc: 0.8334 - val_loss: 0.3875\n",
      "Epoch 45/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8382 - loss: 0.3769 - val_acc: 0.8326 - val_loss: 0.3853\n",
      "Epoch 46/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8440 - loss: 0.3686 - val_acc: 0.8345 - val_loss: 0.3835\n",
      "Epoch 47/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8497 - loss: 0.3666 - val_acc: 0.8349 - val_loss: 0.3821\n",
      "Epoch 48/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8536 - loss: 0.3577 - val_acc: 0.8376 - val_loss: 0.3808\n",
      "Epoch 49/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8503 - loss: 0.3642 - val_acc: 0.8372 - val_loss: 0.3791\n",
      "Epoch 50/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8503 - loss: 0.3557 - val_acc: 0.8406 - val_loss: 0.3778\n",
      "Epoch 51/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8520 - loss: 0.3527 - val_acc: 0.8417 - val_loss: 0.3763\n",
      "Epoch 52/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - loss: 0.3494 - val_acc: 0.8436 - val_loss: 0.3751\n",
      "Epoch 53/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8520 - loss: 0.3590 - val_acc: 0.8429 - val_loss: 0.3738\n",
      "Epoch 54/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8545 - loss: 0.3511 - val_acc: 0.8444 - val_loss: 0.3731\n",
      "Epoch 55/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8536 - loss: 0.3496 - val_acc: 0.8466 - val_loss: 0.3717\n",
      "Epoch 56/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8565 - loss: 0.3551 - val_acc: 0.8489 - val_loss: 0.3710\n",
      "Epoch 57/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8524 - loss: 0.3503 - val_acc: 0.8482 - val_loss: 0.3700\n",
      "Epoch 58/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8527 - loss: 0.3533 - val_acc: 0.8489 - val_loss: 0.3694\n",
      "Epoch 59/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8600 - loss: 0.3465 - val_acc: 0.8478 - val_loss: 0.3691\n",
      "Epoch 60/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8518 - loss: 0.3541 - val_acc: 0.8512 - val_loss: 0.3693\n",
      "Epoch 61/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8523 - loss: 0.3449 - val_acc: 0.8463 - val_loss: 0.3679\n",
      "Epoch 62/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8554 - loss: 0.3469 - val_acc: 0.8501 - val_loss: 0.3676\n",
      "Epoch 63/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8590 - loss: 0.3420 - val_acc: 0.8542 - val_loss: 0.3680\n",
      "Epoch 64/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8587 - loss: 0.3404 - val_acc: 0.8489 - val_loss: 0.3669\n",
      "Epoch 65/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8613 - loss: 0.3436 - val_acc: 0.8485 - val_loss: 0.3666\n",
      "Epoch 66/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8668 - loss: 0.3323 - val_acc: 0.8542 - val_loss: 0.3666\n",
      "Epoch 67/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8596 - loss: 0.3452 - val_acc: 0.8542 - val_loss: 0.3662\n",
      "Epoch 68/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8627 - loss: 0.3391 - val_acc: 0.8542 - val_loss: 0.3665\n",
      "Epoch 69/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8661 - loss: 0.3367 - val_acc: 0.8501 - val_loss: 0.3657\n",
      "Epoch 70/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8597 - loss: 0.3405 - val_acc: 0.8546 - val_loss: 0.3657\n",
      "Epoch 71/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8499 - loss: 0.3582 - val_acc: 0.8501 - val_loss: 0.3652\n",
      "Epoch 72/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8599 - loss: 0.3478 - val_acc: 0.8504 - val_loss: 0.3649\n",
      "Epoch 73/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8610 - loss: 0.3482 - val_acc: 0.8493 - val_loss: 0.3649\n",
      "Epoch 74/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8597 - loss: 0.3424 - val_acc: 0.8497 - val_loss: 0.3650\n",
      "Epoch 75/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8620 - loss: 0.3410 - val_acc: 0.8504 - val_loss: 0.3650\n",
      "Epoch 76/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8575 - loss: 0.3441 - val_acc: 0.8512 - val_loss: 0.3649\n",
      "Epoch 77/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8540 - loss: 0.3531 - val_acc: 0.8535 - val_loss: 0.3647\n",
      "Epoch 78/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8566 - loss: 0.3463 - val_acc: 0.8538 - val_loss: 0.3651\n",
      "Epoch 79/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8661 - loss: 0.3322 - val_acc: 0.8542 - val_loss: 0.3654\n",
      "Epoch 80/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8575 - loss: 0.3453 - val_acc: 0.8546 - val_loss: 0.3656\n",
      "Epoch 81/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8585 - loss: 0.3450 - val_acc: 0.8546 - val_loss: 0.3649\n",
      "Epoch 82/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8572 - loss: 0.3434 - val_acc: 0.8546 - val_loss: 0.3644\n",
      "Epoch 83/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8618 - loss: 0.3317 - val_acc: 0.8542 - val_loss: 0.3645\n",
      "Epoch 84/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8604 - loss: 0.3361 - val_acc: 0.8535 - val_loss: 0.3652\n",
      "Epoch 85/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8644 - loss: 0.3184 - val_acc: 0.8542 - val_loss: 0.3647\n",
      "Epoch 86/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8564 - loss: 0.3515 - val_acc: 0.8512 - val_loss: 0.3640\n",
      "Epoch 87/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8620 - loss: 0.3405 - val_acc: 0.8523 - val_loss: 0.3642\n",
      "Epoch 88/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8612 - loss: 0.3352 - val_acc: 0.8535 - val_loss: 0.3646\n",
      "Epoch 89/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8597 - loss: 0.3407 - val_acc: 0.8519 - val_loss: 0.3638\n",
      "Epoch 90/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8629 - loss: 0.3351 - val_acc: 0.8519 - val_loss: 0.3637\n",
      "Epoch 91/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8625 - loss: 0.3364 - val_acc: 0.8535 - val_loss: 0.3642\n",
      "Epoch 92/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8655 - loss: 0.3433 - val_acc: 0.8546 - val_loss: 0.3646\n",
      "Epoch 93/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8550 - loss: 0.3343 - val_acc: 0.8519 - val_loss: 0.3640\n",
      "Epoch 94/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8635 - loss: 0.3335 - val_acc: 0.8531 - val_loss: 0.3644\n",
      "Epoch 95/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8623 - loss: 0.3308 - val_acc: 0.8516 - val_loss: 0.3641\n",
      "Epoch 96/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8576 - loss: 0.3417 - val_acc: 0.8508 - val_loss: 0.3638\n",
      "Epoch 97/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8606 - loss: 0.3403 - val_acc: 0.8512 - val_loss: 0.3640\n",
      "Epoch 98/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8637 - loss: 0.3322 - val_acc: 0.8519 - val_loss: 0.3642\n",
      "Epoch 99/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8535 - loss: 0.3558 - val_acc: 0.8516 - val_loss: 0.3636\n",
      "Epoch 100/100\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8680 - loss: 0.3238 - val_acc: 0.8508 - val_loss: 0.3634\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xXYhAB_MffEU",
    "outputId": "f9f27053-87b5-4622-9058-024fd72bd8e2"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dense.__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m classifier \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Adding the input layer and the first hidden layer\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m, init \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m))\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Adding the second hidden layer\u001b[39;00m\n\u001b[0;32m     49\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m, init \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: Dense.__init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "67EatDXyg6_8",
    "outputId": "5b6f6346-cfd9-4658-b0bb-22db61060ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1508,   87],\n",
       "       [ 198,  207]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UNPKw8mUjO2E",
    "outputId": "5ecfc4ff-507b-4711-9f17-d936971ef4eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erlf6oBojPzx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMHd72LJCmJp8e2sw+mBD8i",
   "include_colab_link": true,
   "mount_file_id": "1xJQNJzjEJXy1v0jL79lnQnNnLOK_sY1M",
   "name": "ANN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
